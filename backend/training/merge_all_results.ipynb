{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd5981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"‚úì Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a36fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== LOAD ALL RESULT FILES ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING ALL RESULT FILES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "base_dir = r\"c:\\Users\\almir\\ai-privacy\\backend\"\n",
    "\n",
    "# File paths\n",
    "files_to_load = {\n",
    "    'baseline': os.path.join(base_dir, 'models_research', 'research_results.json'),\n",
    "    'fl_adult': os.path.join(base_dir, 'models_fl_adult', 'fl_adult_results.json'),\n",
    "    'dp_continue': os.path.join(base_dir, 'models_research_dp_continue', 'dp_continue_results.json')\n",
    "}\n",
    "\n",
    "# Load each file\n",
    "loaded_data = {}\n",
    "for key, filepath in files_to_load.items():\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            loaded_data[key] = json.load(f)\n",
    "        print(f\"‚úì Loaded: {key} from {filepath}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Not found: {key} at {filepath}\")\n",
    "        loaded_data[key] = None\n",
    "\n",
    "print(f\"\\nLoaded {sum(1 for v in loaded_data.values() if v is not None)}/{len(files_to_load)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b36664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== MERGE INTO SINGLE STRUCTURE ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MERGING ALL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "merged_results = {\n",
    "    'metadata': {\n",
    "        'merged_at': datetime.now().isoformat(),\n",
    "        'description': 'Comprehensive experimental results for privacy-preserving ML research',\n",
    "        'datasets': ['diabetes', 'adult'],\n",
    "        'models': ['LR', 'FNN'],\n",
    "        'methods': ['baseline', 'federated_learning', 'differential_privacy']\n",
    "    },\n",
    "    'baseline': None,\n",
    "    'federated_learning': None,\n",
    "    'differential_privacy': None,\n",
    "    'source_files': {}\n",
    "}\n",
    "\n",
    "# Add baseline\n",
    "if loaded_data['baseline']:\n",
    "    merged_results['baseline'] = loaded_data['baseline']\n",
    "    merged_results['source_files']['baseline'] = files_to_load['baseline']\n",
    "    print(\"‚úì Added baseline results\")\n",
    "\n",
    "# Add FL\n",
    "if loaded_data['fl_adult']:\n",
    "    merged_results['federated_learning'] = loaded_data['fl_adult']\n",
    "    merged_results['source_files']['federated_learning'] = files_to_load['fl_adult']\n",
    "    print(\"‚úì Added federated learning results\")\n",
    "\n",
    "# Add DP\n",
    "if loaded_data['dp_continue']:\n",
    "    merged_results['differential_privacy'] = loaded_data['dp_continue']\n",
    "    merged_results['source_files']['differential_privacy'] = files_to_load['dp_continue']\n",
    "    print(\"‚úì Added differential privacy results\")\n",
    "\n",
    "print(f\"\\n‚úÖ Merged structure created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e8ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== SHOW SUMMARY ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MERGED RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä Baseline:\")\n",
    "if merged_results['baseline']:\n",
    "    baseline_configs = 0\n",
    "    for dataset in ['diabetes', 'adult']:\n",
    "        for model in ['LR', 'FNN']:\n",
    "            if dataset in merged_results['baseline']['baseline_results']:\n",
    "                if model in merged_results['baseline']['baseline_results'][dataset]:\n",
    "                    baseline_configs += 1\n",
    "    print(f\"  ‚úì {baseline_configs} configurations (2 datasets √ó 2 models)\")\n",
    "else:\n",
    "    print(\"  ‚úó No baseline results\")\n",
    "\n",
    "print(\"\\nüìä Federated Learning:\")\n",
    "if merged_results['federated_learning']:\n",
    "    fl_configs = len(merged_results['federated_learning']['federated_learning'])\n",
    "    print(f\"  ‚úì {fl_configs} configurations\")\n",
    "    if 'metadata' in merged_results['federated_learning']:\n",
    "        print(f\"  Dataset: {merged_results['federated_learning']['metadata']['dataset']}\")\n",
    "else:\n",
    "    print(\"  ‚úó No FL results\")\n",
    "\n",
    "print(\"\\nüìä Differential Privacy:\")\n",
    "if merged_results['differential_privacy']:\n",
    "    dp_configs = len(merged_results['differential_privacy']['differential_privacy'])\n",
    "    print(f\"  ‚úì {dp_configs} configurations\")\n",
    "    if 'metadata' in merged_results['differential_privacy']:\n",
    "        print(f\"  Epsilon values: {merged_results['differential_privacy']['metadata']['epsilon_values']}\")\n",
    "else:\n",
    "    print(\"  ‚úó No DP results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b8de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== SAVE MERGED FILE ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING MERGED RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "output_path = os.path.join(base_dir, 'all_experimental_results.json')\n",
    "\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(merged_results, f, indent=2, default=lambda x: float(x) if hasattr(x, 'dtype') else x)\n",
    "\n",
    "file_size = os.path.getsize(output_path) / 1024  # KB\n",
    "print(f\"\\n‚úÖ Saved: {output_path}\")\n",
    "print(f\"   File size: {file_size:.1f} KB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. Upload to Kaggle:\")\n",
    "print(\"   - Go to kaggle.com ‚Üí Your Profile ‚Üí Datasets ‚Üí New Dataset\")\n",
    "print(\"   - Upload: all_experimental_results.json\")\n",
    "print(\"   - Name it: 'ai-privacy-all-results' or similar\")\n",
    "print(\"\\n2. Use in comprehensive_analysis.ipynb:\")\n",
    "print(\"   - Add your dataset as input to the notebook\")\n",
    "print(\"   - The analysis notebook will auto-detect and load it\")\n",
    "print(\"\\n3. Or run comprehensive_analysis.ipynb locally:\")\n",
    "print(\"   - It will find this file automatically!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb64437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== OPTIONAL: VALIDATE STRUCTURE ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALIDATION CHECK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "validation_passed = True\n",
    "\n",
    "# Check required keys\n",
    "required_keys = ['metadata', 'baseline', 'federated_learning', 'differential_privacy']\n",
    "for key in required_keys:\n",
    "    if key in merged_results:\n",
    "        print(f\"‚úì Has key: {key}\")\n",
    "    else:\n",
    "        print(f\"‚úó Missing key: {key}\")\n",
    "        validation_passed = False\n",
    "\n",
    "# Check if at least one method has data\n",
    "has_data = any([\n",
    "    merged_results['baseline'] is not None,\n",
    "    merged_results['federated_learning'] is not None,\n",
    "    merged_results['differential_privacy'] is not None\n",
    "])\n",
    "\n",
    "if has_data:\n",
    "    print(\"‚úì Contains experimental data\")\n",
    "else:\n",
    "    print(\"‚úó No experimental data found\")\n",
    "    validation_passed = False\n",
    "\n",
    "if validation_passed:\n",
    "    print(\"\\n‚úÖ Validation PASSED - File is ready to use!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Validation FAILED - Check missing data\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
