{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a97335",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opacus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92bab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== IMPORTS ====================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import kagglehub\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from opacus import PrivacyEngine\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "# Suppress Opacus warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='opacus')\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")\n",
    "\n",
    "# Configuration\n",
    "RANDOM_SEEDS = [42, 123, 456, 789, 1011]\n",
    "N_SPLITS = 5\n",
    "DP_EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "EPSILON_VALUES = [0.5, 1.0, 3.0, 5.0, 10.0]\n",
    "DP_NOISE_MULTIPLIER = 1.0\n",
    "DP_MAX_GRAD_NORM = 1.0\n",
    "DP_DELTA = 1e-5\n",
    "\n",
    "print(\"\\nConfiguration:\")\n",
    "print(f\"  Dataset: ADULT CENSUS INCOME\")\n",
    "print(f\"  Random seeds: {RANDOM_SEEDS}\")\n",
    "print(f\"  Total evaluations per config: {len(RANDOM_SEEDS)} Ã— {N_SPLITS} = {len(RANDOM_SEEDS) * N_SPLITS}\")\n",
    "print(f\"  K-fold splits: {N_SPLITS}\")\n",
    "print(f\"  Privacy budgets (Îµ): {EPSILON_VALUES}\")\n",
    "print(f\"  Models: LR, FNN\")\n",
    "print(f\"  Total configs: 2 models Ã— 5 Îµ values = 10 configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beeedc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== LOAD ADULT DATASET ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING ADULT CENSUS INCOME DATASET FROM KAGGLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Try Kaggle's native dataset access first (for Kaggle notebooks)\n",
    "try:\n",
    "    # On Kaggle, datasets are mounted at /kaggle/input/\n",
    "    adult_paths = glob.glob('/kaggle/input/*/adult.csv')\n",
    "    \n",
    "    if adult_paths:\n",
    "        adult_csv = adult_paths[0]\n",
    "        print(\"âœ“ Using Kaggle native dataset path\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Dataset not found in /kaggle/input/\")\n",
    "        \n",
    "except (FileNotFoundError, IndexError):\n",
    "    # Fallback to kagglehub for local execution\n",
    "    print(\"âœ“ Using kagglehub for dataset download\")\n",
    "    adult_path = kagglehub.dataset_download(\"uciml/adult-census-income\")\n",
    "    adult_csv = f\"{adult_path}/adult.csv\"\n",
    "\n",
    "# Load dataset\n",
    "df_adult = pd.read_csv(adult_csv)\n",
    "print(f\"âœ“ Adult dataset loaded: {df_adult.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== PREPROCESS DATA ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREPROCESSING DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Adult Census Income preprocessing\n",
    "X_adult_df = df_adult.drop(columns=['income'])\n",
    "y_adult = (df_adult['income'] == '>50K').astype(int).values\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_cols = X_adult_df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_adult_df[col] = le.fit_transform(X_adult_df[col].astype(str))\n",
    "\n",
    "# Convert to numpy array\n",
    "X_adult = X_adult_df.values\n",
    "print(f\"âœ“ Adult - Features: {X_adult.shape}, Target: {y_adult.shape}\")\n",
    "print(f\"âœ“ Class distribution: {np.bincount(y_adult)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcb2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== MODEL ARCHITECTURES ====================\n",
    "\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size=2):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes=[128, 64], output_size=2, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    \"\"\"Evaluate model and return accuracy, f1\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    accuracy = accuracy_score(y, predicted.cpu().numpy())\n",
    "    f1 = f1_score(y, predicted.cpu().numpy(), average='weighted', zero_division=0)\n",
    "    \n",
    "    return accuracy, f1\n",
    "\n",
    "print(\"âœ“ Model architectures defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dcb49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== DIFFERENTIAL PRIVACY TRAINING - ADULT DATASET ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DIFFERENTIAL PRIVACY WITH CROSS-VALIDATION - ADULT DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create models directory\n",
    "try:\n",
    "    models_dir = \"/kaggle/working/models_dp_adult\"\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "except:\n",
    "    models_dir = os.path.join(r\"c:\\Users\\almir\\ai-privacy\\backend\", \"models_dp_adult\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\nResults will be saved to: {models_dir}\")\n",
    "\n",
    "MODEL_TYPES = ['LR', 'FNN']\n",
    "dp_results = {}\n",
    "\n",
    "print(f\"\\nâœ“ Running all Adult DP configurations:\")\n",
    "print(f\"  - Models: {MODEL_TYPES}\")\n",
    "print(f\"  - Epsilon values: {EPSILON_VALUES}\")\n",
    "print(f\"  - Total: {len(MODEL_TYPES)} models Ã— {len(EPSILON_VALUES)} Îµ = {len(MODEL_TYPES) * len(EPSILON_VALUES)} configurations\")\n",
    "print(f\"  - Total evaluations: {len(MODEL_TYPES) * len(EPSILON_VALUES) * len(RANDOM_SEEDS) * N_SPLITS} (10 configs Ã— 25 evals)\")\n",
    "\n",
    "checkpoint_path = os.path.join(models_dir, 'dp_adult_checkpoint.json')\n",
    "\n",
    "for model_type in MODEL_TYPES:\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"Model: {model_type}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for target_epsilon in EPSILON_VALUES:\n",
    "        config_key = f\"adult_{model_type}_DP_eps{target_epsilon}\"\n",
    "        \n",
    "        print(f\"\\n  Target Îµ: {target_epsilon}\")\n",
    "        \n",
    "        all_accuracies = []\n",
    "        all_f1s = []\n",
    "        all_epsilons = []\n",
    "        \n",
    "        for run_idx in range(len(RANDOM_SEEDS)):\n",
    "            seed = RANDOM_SEEDS[run_idx]\n",
    "            skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=seed)\n",
    "            \n",
    "            for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_adult, y_adult)):\n",
    "                X_train, X_val = X_adult[train_idx], X_adult[val_idx]\n",
    "                y_train, y_val = y_adult[train_idx], y_adult[val_idx]\n",
    "                \n",
    "                # Scale features\n",
    "                scaler = StandardScaler()\n",
    "                X_train_scaled = scaler.fit_transform(X_train)\n",
    "                X_val_scaled = scaler.transform(X_val)\n",
    "                \n",
    "                # Create DataLoader\n",
    "                train_dataset = TensorDataset(\n",
    "                    torch.FloatTensor(X_train_scaled),\n",
    "                    torch.LongTensor(y_train)\n",
    "                )\n",
    "                train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "                \n",
    "                # Initialize model\n",
    "                input_size = X_train_scaled.shape[1]\n",
    "                if model_type == 'LR':\n",
    "                    model = LogisticRegressionModel(input_size, output_size=2)\n",
    "                else:\n",
    "                    model = FeedforwardNN(input_size, hidden_sizes=[128, 64], output_size=2)\n",
    "                \n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "                loss_fn = nn.CrossEntropyLoss()\n",
    "                \n",
    "                # Attach DP\n",
    "                privacy_engine = PrivacyEngine()\n",
    "                dp_model, optimizer, train_loader_dp = privacy_engine.make_private(\n",
    "                    module=model,\n",
    "                    optimizer=optimizer,\n",
    "                    data_loader=train_loader,\n",
    "                    noise_multiplier=DP_NOISE_MULTIPLIER,\n",
    "                    max_grad_norm=DP_MAX_GRAD_NORM,\n",
    "                )\n",
    "                \n",
    "                # Training\n",
    "                current_epsilon = 0\n",
    "                for epoch in range(DP_EPOCHS):\n",
    "                    dp_model.train()\n",
    "                    for batch_x, batch_y in train_loader_dp:\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = dp_model(batch_x)\n",
    "                        loss = loss_fn(outputs, batch_y)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    current_epsilon = privacy_engine.get_epsilon(DP_DELTA)\n",
    "                    \n",
    "                    # Stop if reached target epsilon\n",
    "                    if current_epsilon >= target_epsilon:\n",
    "                        break\n",
    "                \n",
    "                # Evaluate\n",
    "                accuracy, f1 = evaluate_model(dp_model, X_val_scaled, y_val)\n",
    "                all_accuracies.append(accuracy)\n",
    "                all_f1s.append(f1)\n",
    "                all_epsilons.append(current_epsilon)\n",
    "                \n",
    "                if fold_idx == N_SPLITS - 1:\n",
    "                    print(f\"    Run {run_idx + 1}, Fold {fold_idx + 1}: Acc={accuracy:.4f}, Îµ={current_epsilon:.3f}\")\n",
    "        \n",
    "        # Statistics\n",
    "        acc_mean = np.mean(all_accuracies)\n",
    "        acc_std = np.std(all_accuracies, ddof=1)\n",
    "        acc_min = np.min(all_accuracies)\n",
    "        acc_max = np.max(all_accuracies)\n",
    "        f1_mean = np.mean(all_f1s)\n",
    "        f1_std = np.std(all_f1s, ddof=1)\n",
    "        eps_mean = np.mean(all_epsilons)\n",
    "        \n",
    "        dp_results[config_key] = {\n",
    "            'dataset': 'adult',\n",
    "            'model': model_type,\n",
    "            'target_epsilon': target_epsilon,\n",
    "            'actual_epsilon': eps_mean,\n",
    "            'accuracy': {'mean': acc_mean, 'std': acc_std, 'min': acc_min, 'max': acc_max},\n",
    "            'f1': {'mean': f1_mean, 'std': f1_std},\n",
    "            'all_accuracies': all_accuracies,\n",
    "            'all_f1s': all_f1s\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n  âœ“ DP Îµ={target_epsilon} Results:\")\n",
    "        print(f\"    Accuracy: {acc_mean*100:.2f}% Â± {acc_std*100:.2f}% (range: {acc_min*100:.2f}% - {acc_max*100:.2f}%)\")\n",
    "        print(f\"    F1-Score: {f1_mean*100:.2f}% Â± {f1_std*100:.2f}%\")\n",
    "        print(f\"    Actual Îµ: {eps_mean:.3f}\")\n",
    "        \n",
    "        # Save checkpoint after each config\n",
    "        checkpoint_data = {\n",
    "            'dp_results': dp_results,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'last_completed': config_key\n",
    "        }\n",
    "        with open(checkpoint_path, 'w') as f:\n",
    "            json.dump(checkpoint_data, f, indent=2, default=lambda x: float(x) if isinstance(x, np.floating) else x)\n",
    "        print(f\"    ðŸ’¾ Checkpoint saved\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DIFFERENTIAL PRIVACY PHASE COMPLETE - ALL ADULT CONFIGS DONE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18be8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== STATISTICAL ANALYSIS & COMPARISON ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load baseline results\n",
    "try:\n",
    "    baseline_path = \"/kaggle/input/ai-privacy-baseline-results/research_results.json\"\n",
    "    with open(baseline_path, 'r') as f:\n",
    "        baseline_data = json.load(f)\n",
    "except:\n",
    "    baseline_path = os.path.join(r\"c:\\Users\\almir\\ai-privacy\\backend\", \"models_research\", \"research_results.json\")\n",
    "    with open(baseline_path, 'r') as f:\n",
    "        baseline_data = json.load(f)\n",
    "\n",
    "baseline_results = {}\n",
    "for model in ['LR', 'FNN']:\n",
    "    key = f\"adult_{model}\"\n",
    "    baseline_results[key] = {\n",
    "        'accuracy': baseline_data['baseline_results']['adult'][model]['accuracy']['mean'],\n",
    "        'all_accuracies': baseline_data['baseline_results']['adult'][model]['all_accuracies']\n",
    "    }\n",
    "\n",
    "print(\"\\nâœ“ Baseline results loaded\")\n",
    "\n",
    "# DP vs Baseline comparisons\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DIFFERENTIAL PRIVACY vs BASELINE - Statistical Tests\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "dp_comparison = []\n",
    "for config_key, dp_data in dp_results.items():\n",
    "    baseline_key = f\"adult_{dp_data['model']}\"\n",
    "    baseline_acc = baseline_results[baseline_key]['accuracy']\n",
    "    baseline_all = baseline_results[baseline_key]['all_accuracies']\n",
    "    \n",
    "    dp_acc = dp_data['accuracy']['mean']\n",
    "    dp_all = dp_data['all_accuracies']\n",
    "    accuracy_loss = baseline_acc - dp_acc\n",
    "    \n",
    "    # T-test\n",
    "    t_stat, p_value = stats.ttest_ind(baseline_all, dp_all)\n",
    "    \n",
    "    dp_comparison.append({\n",
    "        'Model': dp_data['model'],\n",
    "        'Epsilon': dp_data['target_epsilon'],\n",
    "        'DP_Accuracy': dp_acc * 100,\n",
    "        'DP_Std': dp_data['accuracy']['std'] * 100,\n",
    "        'Baseline': baseline_acc * 100,\n",
    "        'Accuracy_Loss': accuracy_loss * 100,\n",
    "        't_statistic': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'Significant': 'Yes' if p_value < 0.05 else 'No'\n",
    "    })\n",
    "\n",
    "dp_comparison_df = pd.DataFrame(dp_comparison)\n",
    "print(\"\\n\" + dp_comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b05dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== SAVE RESULTS ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save comprehensive JSON\n",
    "results_json = {\n",
    "    'metadata': {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'dataset': 'adult',\n",
    "        'random_seeds': RANDOM_SEEDS,\n",
    "        'n_splits': N_SPLITS,\n",
    "        'total_evaluations': len(RANDOM_SEEDS) * N_SPLITS,\n",
    "        'epsilon_values': EPSILON_VALUES,\n",
    "        'dp_epochs': DP_EPOCHS,\n",
    "        'models': MODEL_TYPES,\n",
    "        'total_configs': len(MODEL_TYPES) * len(EPSILON_VALUES)\n",
    "    },\n",
    "    'differential_privacy': dp_results,\n",
    "    'baseline_reference': baseline_results\n",
    "}\n",
    "\n",
    "json_path = os.path.join(models_dir, 'dp_adult_results.json')\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(results_json, f, indent=2, default=lambda x: float(x) if isinstance(x, np.floating) else x)\n",
    "print(f\"âœ“ Saved: dp_adult_results.json\")\n",
    "\n",
    "# Save comparison CSV\n",
    "dp_csv_path = os.path.join(models_dir, 'dp_adult_vs_baseline.csv')\n",
    "dp_comparison_df.to_csv(dp_csv_path, index=False)\n",
    "print(f\"âœ“ Saved: dp_adult_vs_baseline.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL RESULTS SAVED\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a60b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== VISUALIZATIONS ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# DP Privacy-Accuracy Tradeoff for Adult Dataset\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 7))\n",
    "fig.suptitle('Adult Dataset: Differential Privacy Privacy-Accuracy Tradeoff\\n5-Fold CV Ã— 5 Runs', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "for model in ['LR', 'FNN']:\n",
    "    subset = dp_comparison_df[dp_comparison_df['Model'] == model]\n",
    "    \n",
    "    ax.errorbar(subset['Epsilon'], subset['DP_Accuracy'], yerr=subset['DP_Std'], \n",
    "                marker='o', capsize=5, label=model, linewidth=2.5, markersize=10)\n",
    "\n",
    "# Baseline lines\n",
    "baseline_lr = baseline_results['adult_LR']['accuracy'] * 100\n",
    "baseline_fnn = baseline_results['adult_FNN']['accuracy'] * 100\n",
    "ax.axhline(y=baseline_lr, color='blue', linestyle='--', alpha=0.5, linewidth=2, label='LR Baseline')\n",
    "ax.axhline(y=baseline_fnn, color='orange', linestyle='--', alpha=0.5, linewidth=2, label='FNN Baseline')\n",
    "\n",
    "ax.set_xlabel('Privacy Budget (Îµ)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Adult Census Income Dataset', fontsize=14)\n",
    "ax.legend(fontsize=12, loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "dp_viz_path = os.path.join(models_dir, 'dp_adult_privacy_accuracy_tradeoff.png')\n",
    "plt.savefig(dp_viz_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"âœ“ Saved: dp_adult_privacy_accuracy_tradeoff.png\")\n",
    "plt.show()\n",
    "\n",
    "# Accuracy Loss Heatmap\n",
    "print(\"\\nâœ“ Generating accuracy loss heatmap...\")\n",
    "pivot_data = dp_comparison_df.pivot(index='Model', columns='Epsilon', values='Accuracy_Loss')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "sns.heatmap(pivot_data, annot=True, fmt='.2f', cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Accuracy Loss (%)'}, ax=ax)\n",
    "ax.set_title('Adult Dataset: Accuracy Loss vs Baseline (%)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Privacy Budget (Îµ)', fontsize=12)\n",
    "ax.set_ylabel('Model', fontsize=12)\n",
    "\n",
    "heatmap_path = os.path.join(models_dir, 'dp_adult_accuracy_loss_heatmap.png')\n",
    "plt.savefig(heatmap_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"âœ“ Saved: dp_adult_accuracy_loss_heatmap.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VISUALIZATIONS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a1053b",
   "metadata": {},
   "source": [
    "## Summary - Adult Dataset Differential Privacy\n",
    "\n",
    "This notebook completed **ALL Adult DP configurations**:\n",
    "\n",
    "### **Configurations**\n",
    "- **Models:** Logistic Regression (LR), Feedforward Neural Network (FNN)\n",
    "- **Privacy budgets (Îµ):** [0.5, 1.0, 3.0, 5.0, 10.0]\n",
    "- **Total configs:** 2 models Ã— 5 Îµ values = **10 configurations**\n",
    "- **Total evaluations:** 10 configs Ã— 25 evals = **250 evaluations**\n",
    "\n",
    "### **Results saved to:**\n",
    "- `/kaggle/working/models_dp_adult/` (Kaggle)\n",
    "- `c:\\Users\\almir\\ai-privacy\\backend\\models_dp_adult\\` (Local)\n",
    "\n",
    "### **Output files:**\n",
    "1. `dp_adult_results.json` - Complete results with all metrics\n",
    "2. `dp_adult_vs_baseline.csv` - Statistical comparison\n",
    "3. `dp_adult_privacy_accuracy_tradeoff.png` - Visualization\n",
    "4. `dp_adult_accuracy_loss_heatmap.png` - Heatmap\n",
    "5. `dp_adult_checkpoint.json` - Checkpoints (crash recovery)\n",
    "\n",
    "### **Next steps:**\n",
    "- Merge with other DP results (diabetes)\n",
    "- Upload to Kaggle for comprehensive analysis\n",
    "- Include in final research paper"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
