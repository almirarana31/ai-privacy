{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346fd193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== LOAD DATASETS ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING DATASETS FROM KAGGLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import glob\n",
    "\n",
    "# Try Kaggle's native dataset access first (for Kaggle notebooks)\n",
    "try:\n",
    "    # On Kaggle, datasets are mounted at /kaggle/input/\n",
    "    diabetes_paths = glob.glob('/kaggle/input/*/diabetes_binary_health_indicators_BRFSS2015.csv')\n",
    "    adult_paths = glob.glob('/kaggle/input/*/adult.csv')\n",
    "    \n",
    "    if diabetes_paths and adult_paths:\n",
    "        diabetes_csv = diabetes_paths[0]\n",
    "        adult_csv = adult_paths[0]\n",
    "        print(\"‚úì Using Kaggle native dataset paths\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Datasets not found in /kaggle/input/\")\n",
    "        \n",
    "except (FileNotFoundError, IndexError):\n",
    "    # Fallback to kagglehub for local execution\n",
    "    print(\"‚úì Using kagglehub for dataset download\")\n",
    "    import kagglehub\n",
    "    \n",
    "    diabetes_path = kagglehub.dataset_download(\"alexteboul/diabetes-health-indicators-dataset\")\n",
    "    diabetes_csv = f\"{diabetes_path}/diabetes_binary_health_indicators_BRFSS2015.csv\"\n",
    "    \n",
    "    adult_path = kagglehub.dataset_download(\"uciml/adult-census-income\")\n",
    "    adult_csv = f\"{adult_path}/adult.csv\"\n",
    "\n",
    "# Load datasets\n",
    "df_diabetes = pd.read_csv(diabetes_csv)\n",
    "print(f\"‚úì Diabetes dataset loaded: {df_diabetes.shape}\")\n",
    "\n",
    "df_adult = pd.read_csv(adult_csv)\n",
    "print(f\"‚úì Adult dataset loaded: {df_adult.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d19b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== PREPROCESS DATA ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREPROCESSING DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Diabetes\n",
    "X_diabetes = df_diabetes.drop(columns=['Diabetes_binary']).values\n",
    "y_diabetes = df_diabetes['Diabetes_binary'].values\n",
    "print(f\"‚úì Diabetes - Features: {X_diabetes.shape}, Target: {y_diabetes.shape}\")\n",
    "\n",
    "# Adult\n",
    "X_adult_df = df_adult.drop(columns=['income'])\n",
    "y_adult = (df_adult['income'] == '>50K').astype(int).values\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_cols = X_adult_df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_adult_df[col] = le.fit_transform(X_adult_df[col].astype(str))\n",
    "\n",
    "# Convert to numpy array\n",
    "X_adult = X_adult_df.values\n",
    "print(f\"‚úì Adult - Features: {X_adult.shape}, Target: {y_adult.shape}\")\n",
    "\n",
    "# Verify both are numpy arrays\n",
    "print(f\"\\n‚úì Data types verified:\")\n",
    "print(f\"  X_diabetes: {type(X_diabetes)}\")\n",
    "print(f\"  X_adult: {type(X_adult)}\")\n",
    "print(f\"  y_diabetes: {type(y_diabetes)}\")\n",
    "print(f\"  y_adult: {type(y_adult)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8650552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== MODEL ARCHITECTURES ====================\n",
    "\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size=2):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes=[128, 64], output_size=2, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "print(\"‚úì Model architectures defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40645ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== FEDERATED LEARNING UTILITIES ====================\n",
    "\n",
    "def fedavg_aggregate(client_models, client_data_sizes):\n",
    "    \"\"\"FedAvg: Weighted average based on client data sizes\"\"\"\n",
    "    total_size = sum(client_data_sizes)\n",
    "    global_state = {}\n",
    "    \n",
    "    for key in client_models[0].state_dict().keys():\n",
    "        global_state[key] = sum(\n",
    "            client_models[i].state_dict()[key] * (client_data_sizes[i] / total_size)\n",
    "            for i in range(len(client_models))\n",
    "        )\n",
    "    \n",
    "    return global_state\n",
    "\n",
    "def fedprox_aggregate(client_models, client_data_sizes):\n",
    "    \"\"\"FedProx: Similar to FedAvg\"\"\"\n",
    "    return fedavg_aggregate(client_models, client_data_sizes)\n",
    "\n",
    "def qfedavg_aggregate(client_models, client_losses, q=0.2):\n",
    "    \"\"\"q-FedAvg: Fairness-weighted aggregation\"\"\"\n",
    "    lipschitz = [1.0 / (loss + 1e-10) for loss in client_losses]\n",
    "    weights = [l ** q for l in lipschitz]\n",
    "    total_weight = sum(weights)\n",
    "    \n",
    "    global_state = {}\n",
    "    for key in client_models[0].state_dict().keys():\n",
    "        global_state[key] = sum(\n",
    "            client_models[i].state_dict()[key] * (weights[i] / total_weight)\n",
    "            for i in range(len(client_models))\n",
    "        )\n",
    "    \n",
    "    return global_state\n",
    "\n",
    "def scaffold_aggregate(client_models, client_data_sizes):\n",
    "    \"\"\"SCAFFOLD: Simplified version\"\"\"\n",
    "    return fedavg_aggregate(client_models, client_data_sizes)\n",
    "\n",
    "# FedAdam state\n",
    "fedadam_state = {'m': None, 'v': None, 't': 0}\n",
    "\n",
    "def fedadam_aggregate(client_models, client_data_sizes, beta1=0.9, beta2=0.999, eta=0.01, tau=1e-3):\n",
    "    \"\"\"FedAdam: Adaptive federated optimization\"\"\"\n",
    "    total_size = sum(client_data_sizes)\n",
    "    avg_state = {}\n",
    "    \n",
    "    # Get device from first model\n",
    "    device = next(client_models[0].parameters()).device\n",
    "    \n",
    "    for key in client_models[0].state_dict().keys():\n",
    "        avg_state[key] = sum(\n",
    "            client_models[i].state_dict()[key] * (client_data_sizes[i] / total_size)\n",
    "            for i in range(len(client_models))\n",
    "        )\n",
    "    \n",
    "    if fedadam_state['m'] is None:\n",
    "        fedadam_state['m'] = {key: torch.zeros_like(val).to(device) for key, val in avg_state.items()}\n",
    "        fedadam_state['v'] = {key: torch.zeros_like(val).to(device) for key, val in avg_state.items()}\n",
    "    \n",
    "    fedadam_state['t'] += 1\n",
    "    global_state = {}\n",
    "    \n",
    "    for key in avg_state.keys():\n",
    "        delta = avg_state[key]\n",
    "        # Ensure state tensors are on the same device\n",
    "        fedadam_state['m'][key] = fedadam_state['m'][key].to(device)\n",
    "        fedadam_state['v'][key] = fedadam_state['v'][key].to(device)\n",
    "        \n",
    "        fedadam_state['m'][key] = beta1 * fedadam_state['m'][key] + (1 - beta1) * delta\n",
    "        fedadam_state['v'][key] = beta2 * fedadam_state['v'][key] + (1 - beta2) * (delta ** 2)\n",
    "        \n",
    "        m_hat = fedadam_state['m'][key] / (1 - beta1 ** fedadam_state['t'])\n",
    "        v_hat = fedadam_state['v'][key] / (1 - beta2 ** fedadam_state['t'])\n",
    "        \n",
    "        global_state[key] = avg_state[key] + eta * m_hat / (torch.sqrt(v_hat) + tau)\n",
    "    \n",
    "    return global_state\n",
    "\n",
    "def train_fl_client(client_model, train_loader, global_model=None, epochs=5, lr=0.001, mu=0.01, use_proximal=False):\n",
    "    \"\"\"Train a single FL client\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    client_model = client_model.to(device)\n",
    "    \n",
    "    # Move global model to same device if using FedProx\n",
    "    if use_proximal and global_model is not None:\n",
    "        global_model = global_model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(client_model.parameters(), lr=lr)\n",
    "    \n",
    "    client_model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = client_model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            # FedProx proximal term\n",
    "            if use_proximal and global_model is not None:\n",
    "                proximal_term = 0.0\n",
    "                for w, w_t in zip(client_model.parameters(), global_model.parameters()):\n",
    "                    proximal_term += (w - w_t).norm(2)\n",
    "                loss += (mu / 2) * proximal_term\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        total_loss += epoch_loss / len(train_loader)\n",
    "    \n",
    "    return client_model, total_loss / epochs\n",
    "\n",
    "def distribute_data_to_clients(X, y, num_clients, batch_size):\n",
    "    \"\"\"Distribute data IID to clients\"\"\"\n",
    "    dataset = TensorDataset(torch.FloatTensor(X), torch.LongTensor(y))\n",
    "    \n",
    "    total_size = len(dataset)\n",
    "    client_sizes = [total_size // num_clients] * num_clients\n",
    "    client_sizes[-1] += total_size % num_clients\n",
    "    \n",
    "    indices = torch.randperm(total_size).tolist()\n",
    "    client_loaders = []\n",
    "    start_idx = 0\n",
    "    \n",
    "    for size in client_sizes:\n",
    "        client_indices = indices[start_idx:start_idx + size]\n",
    "        client_dataset = Subset(dataset, client_indices)\n",
    "        client_loader = DataLoader(client_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        client_loaders.append(client_loader)\n",
    "        start_idx += size\n",
    "    \n",
    "    return client_loaders, client_sizes\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    \"\"\"Evaluate model and return accuracy, f1\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    accuracy = accuracy_score(y, predicted.cpu().numpy())\n",
    "    f1 = f1_score(y, predicted.cpu().numpy(), average='weighted', zero_division=0)\n",
    "    \n",
    "    return accuracy, f1\n",
    "\n",
    "print(\"‚úì FL utilities defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf1bd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== PHASE 1: FEDERATED LEARNING - 5-FOLD CV √ó 5 RUNS ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 1: FEDERATED LEARNING WITH CROSS-VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create models directory (works on both Windows and Linux/Kaggle)\n",
    "try:\n",
    "    # Try Kaggle/Linux path first\n",
    "    models_dir = \"/kaggle/working/models_fl_continue\"\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "except:\n",
    "    # Fallback to Windows path for local execution\n",
    "    models_dir = os.path.join(r\"c:\\Users\\almir\\ai-privacy\\backend\", \"models_fl_continue\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\nModels will be saved to: {models_dir}\")\n",
    "print(f\"Total expected evaluations per config: {len(RANDOM_SEEDS)} seeds √ó {N_SPLITS} folds = {len(RANDOM_SEEDS) * N_SPLITS}\")\n",
    "\n",
    "# Safety check: Ensure data is numpy arrays, not DataFrames\n",
    "if isinstance(X_diabetes, pd.DataFrame):\n",
    "    X_diabetes = X_diabetes.values\n",
    "if isinstance(y_diabetes, pd.Series):\n",
    "    y_diabetes = y_diabetes.values\n",
    "if isinstance(X_adult, pd.DataFrame):\n",
    "    X_adult = X_adult.values\n",
    "if isinstance(y_adult, pd.Series):\n",
    "    y_adult = y_adult.values\n",
    "\n",
    "print(f\"\\n‚úì Data format verified:\")\n",
    "print(f\"  X_diabetes: {type(X_diabetes)} shape {X_diabetes.shape}\")\n",
    "print(f\"  X_adult: {type(X_adult)} shape {X_adult.shape}\")\n",
    "\n",
    "DATASETS = {'diabetes': (X_diabetes, y_diabetes), 'adult': (X_adult, y_adult)}\n",
    "MODEL_TYPES = ['LR', 'FNN']\n",
    "AGGREGATION_METHODS = ['FedAvg', 'FedProx', 'q-FedAvg', 'SCAFFOLD', 'FedAdam']\n",
    "\n",
    "# Initialize checkpoint - Resume after FedProx (skip FedAvg and FedProx)\n",
    "fl_results = {\n",
    "    'diabetes_LR_FedAvg': {'dataset': 'diabetes', 'model': 'LR', 'aggregation': 'FedAvg'},\n",
    "    'diabetes_LR_FedProx': {'dataset': 'diabetes', 'model': 'LR', 'aggregation': 'FedProx'}\n",
    "}\n",
    "resume_from = {'dataset': 'diabetes', 'model': 'LR', 'aggregation': 'q-FedAvg', 'found': False}\n",
    "print(\"\\n‚úì Checkpoint initialized - Resuming from Diabetes LR q-FedAvg\")\n",
    "\n",
    "checkpoint_path = os.path.join(models_dir, 'fl_checkpoint.json')\n",
    "\n",
    "for dataset_name, (X_data, y_data) in DATASETS.items():\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"Dataset: {dataset_name.upper()}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for model_type in MODEL_TYPES:\n",
    "        print(f\"\\n  Model: {model_type}\")\n",
    "        \n",
    "        for agg_method in AGGREGATION_METHODS:\n",
    "            # Skip if already completed (checkpoint resume)\n",
    "            config_key = f\"{dataset_name}_{model_type}_{agg_method}\"\n",
    "            if config_key in fl_results:\n",
    "                print(f\"\\n    Aggregation: {agg_method} - ‚úì SKIPPED (already completed)\")\n",
    "                continue\n",
    "            \n",
    "            # Skip if before resume point\n",
    "            if resume_from is not None:\n",
    "                if (dataset_name != resume_from['dataset'] or \n",
    "                    model_type != resume_from['model'] or \n",
    "                    agg_method != resume_from['aggregation']):\n",
    "                    if resume_from.get('found', False):\n",
    "                        pass  # Already past resume point, continue normally\n",
    "                    else:\n",
    "                        print(f\"\\n    Aggregation: {agg_method} - ‚è≠Ô∏è  SKIPPING (before resume point)\")\n",
    "                        continue\n",
    "                else:\n",
    "                    resume_from['found'] = True\n",
    "                    print(f\"\\n    Aggregation: {agg_method} - üîÑ RESUMING FROM HERE\")\n",
    "            else:\n",
    "                print(f\"\\n    Aggregation: {agg_method}\")\n",
    "            \n",
    "            all_accuracies = []\n",
    "            all_f1s = []\n",
    "            \n",
    "            # Reset FedAdam state\n",
    "            fedadam_state['m'] = None\n",
    "            fedadam_state['v'] = None\n",
    "            fedadam_state['t'] = 0\n",
    "            \n",
    "            for run_idx, seed in enumerate(RANDOM_SEEDS):\n",
    "                # K-Fold split\n",
    "                skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=seed)\n",
    "                \n",
    "                for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_data, y_data)):\n",
    "                    X_train, X_val = X_data[train_idx], X_data[val_idx]\n",
    "                    y_train, y_val = y_data[train_idx], y_data[val_idx]\n",
    "                    \n",
    "                    # Scale features\n",
    "                    scaler = StandardScaler()\n",
    "                    X_train_scaled = scaler.fit_transform(X_train)\n",
    "                    X_val_scaled = scaler.transform(X_val)\n",
    "                    \n",
    "                    # Distribute data to clients\n",
    "                    client_loaders, client_sizes = distribute_data_to_clients(\n",
    "                        X_train_scaled, y_train, NUM_CLIENTS, BATCH_SIZE\n",
    "                    )\n",
    "                    \n",
    "                    # Initialize global model\n",
    "                    input_size = X_train_scaled.shape[1]\n",
    "                    if model_type == 'LR':\n",
    "                        global_model = LogisticRegressionModel(input_size, output_size=2)\n",
    "                    else:\n",
    "                        global_model = FeedforwardNN(input_size, hidden_sizes=[128, 64], output_size=2)\n",
    "                    \n",
    "                    # FL Training\n",
    "                    for round_num in range(GLOBAL_ROUNDS):\n",
    "                        client_models = []\n",
    "                        client_losses = []\n",
    "                        \n",
    "                        for client_id in range(NUM_CLIENTS):\n",
    "                            client_model = deepcopy(global_model)\n",
    "                            use_proximal = (agg_method == 'FedProx')\n",
    "                            \n",
    "                            trained_model, loss = train_fl_client(\n",
    "                                client_model, client_loaders[client_id],\n",
    "                                global_model=global_model if use_proximal else None,\n",
    "                                epochs=LOCAL_EPOCHS, lr=LEARNING_RATE, use_proximal=use_proximal\n",
    "                            )\n",
    "                            \n",
    "                            client_models.append(trained_model)\n",
    "                            client_losses.append(loss)\n",
    "                        \n",
    "                        # Aggregate\n",
    "                        if agg_method == 'FedAvg':\n",
    "                            global_state = fedavg_aggregate(client_models, client_sizes)\n",
    "                        elif agg_method == 'FedProx':\n",
    "                            global_state = fedprox_aggregate(client_models, client_sizes)\n",
    "                        elif agg_method == 'q-FedAvg':\n",
    "                            global_state = qfedavg_aggregate(client_models, client_losses)\n",
    "                        elif agg_method == 'SCAFFOLD':\n",
    "                            global_state = scaffold_aggregate(client_models, client_sizes)\n",
    "                        elif agg_method == 'FedAdam':\n",
    "                            global_state = fedadam_aggregate(client_models, client_sizes)\n",
    "                        \n",
    "                        global_model.load_state_dict(global_state)\n",
    "                    \n",
    "                    # Evaluate\n",
    "                    accuracy, f1 = evaluate_model(global_model, X_val_scaled, y_val)\n",
    "                    all_accuracies.append(accuracy)\n",
    "                    all_f1s.append(f1)\n",
    "                    \n",
    "                    if fold_idx == N_SPLITS - 1:\n",
    "                        print(f\"      Run {run_idx + 1}, Fold {fold_idx + 1}: Acc={accuracy:.4f}\")\n",
    "            \n",
    "            # Statistics\n",
    "            acc_mean = np.mean(all_accuracies)\n",
    "            acc_std = np.std(all_accuracies, ddof=1)\n",
    "            acc_min = np.min(all_accuracies)\n",
    "            acc_max = np.max(all_accuracies)\n",
    "            f1_mean = np.mean(all_f1s)\n",
    "            f1_std = np.std(all_f1s, ddof=1)\n",
    "            \n",
    "            config_key = f\"{dataset_name}_{model_type}_{agg_method}\"\n",
    "            fl_results[config_key] = {\n",
    "                'dataset': dataset_name,\n",
    "                'model': model_type,\n",
    "                'aggregation': agg_method,\n",
    "                'accuracy': {'mean': acc_mean, 'std': acc_std, 'min': acc_min, 'max': acc_max},\n",
    "                'f1': {'mean': f1_mean, 'std': f1_std},\n",
    "                'all_accuracies': all_accuracies,\n",
    "                'all_f1s': all_f1s\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n    ‚úì {agg_method} Results:\")\n",
    "            print(f\"      Accuracy: {acc_mean*100:.2f}% ¬± {acc_std*100:.2f}% (range: {acc_min*100:.2f}% - {acc_max*100:.2f}%)\")\n",
    "            print(f\"      F1-Score: {f1_mean*100:.2f}% ¬± {f1_std*100:.2f}%\")\n",
    "            \n",
    "            # Save checkpoint after each aggregation\n",
    "            checkpoint = {\n",
    "                'fl_results': fl_results,\n",
    "                'resume_from': {\n",
    "                    'dataset': dataset_name,\n",
    "                    'model': model_type,\n",
    "                    'aggregation': agg_method,\n",
    "                    'found': True\n",
    "                },\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            with open(checkpoint_path, 'w') as f:\n",
    "                json.dump(checkpoint, f, indent=2, default=lambda x: float(x) if isinstance(x, np.floating) else x)\n",
    "            print(f\"      üíæ Checkpoint saved\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEDERATED LEARNING PHASE COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa6e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== PHASE 2: STATISTICAL ANALYSIS & COMPARISON ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 2: STATISTICAL ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load baseline results from crossvalidations.ipynb\n",
    "try:\n",
    "    # Try Kaggle/Linux path first\n",
    "    baseline_path = \"/kaggle/input/ai-privacy-baseline-results/research_results.json\"\n",
    "    with open(baseline_path, 'r') as f:\n",
    "        baseline_data = json.load(f)\n",
    "except:\n",
    "    # Fallback to Windows path for local execution\n",
    "    baseline_path = os.path.join(r\"c:\\Users\\almir\\ai-privacy\\backend\", \"models_research\", \"research_results.json\")\n",
    "    with open(baseline_path, 'r') as f:\n",
    "        baseline_data = json.load(f)\n",
    "\n",
    "baseline_results = {}\n",
    "for dataset in ['diabetes', 'adult']:\n",
    "    for model in ['LR', 'FNN']:\n",
    "        key = f\"{dataset}_{model}\"\n",
    "        baseline_results[key] = {\n",
    "            'accuracy': baseline_data['baseline_results'][dataset][model]['accuracy']['mean'],\n",
    "            'all_accuracies': baseline_data['baseline_results'][dataset][model]['all_accuracies']\n",
    "        }\n",
    "\n",
    "print(\"\\n‚úì Baseline results loaded\")\n",
    "\n",
    "# FL vs Baseline comparisons\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEDERATED LEARNING vs BASELINE - Statistical Tests\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fl_comparison = []\n",
    "for config_key, fl_data in fl_results.items():\n",
    "    # Skip placeholder entries (those without accuracy data)\n",
    "    if 'accuracy' not in fl_data or 'all_accuracies' not in fl_data:\n",
    "        continue\n",
    "    \n",
    "    baseline_key = f\"{fl_data['dataset']}_{fl_data['model']}\"\n",
    "    baseline_acc = baseline_results[baseline_key]['accuracy']\n",
    "    baseline_all = baseline_results[baseline_key]['all_accuracies']\n",
    "    \n",
    "    fl_acc = fl_data['accuracy']['mean']\n",
    "    fl_all = fl_data['all_accuracies']\n",
    "    accuracy_loss = baseline_acc - fl_acc\n",
    "    \n",
    "    # T-test\n",
    "    t_stat, p_value = stats.ttest_ind(baseline_all, fl_all)\n",
    "    \n",
    "    fl_comparison.append({\n",
    "        'Dataset': fl_data['dataset'],\n",
    "        'Model': fl_data['model'],\n",
    "        'Aggregation': fl_data['aggregation'],\n",
    "        'FL_Accuracy': fl_acc * 100,\n",
    "        'FL_Std': fl_data['accuracy']['std'] * 100,\n",
    "        'Baseline': baseline_acc * 100,\n",
    "        'Accuracy_Loss': accuracy_loss * 100,\n",
    "        't_statistic': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'Significant': 'Yes' if p_value < 0.05 else 'No'\n",
    "    })\n",
    "\n",
    "fl_comparison_df = pd.DataFrame(fl_comparison)\n",
    "print(\"\\n\" + fl_comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b87d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== PHASE 3: SAVE RESULTS ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save comprehensive JSON\n",
    "results_json = {\n",
    "    'metadata': {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'random_seeds': RANDOM_SEEDS,\n",
    "        'n_splits': N_SPLITS,\n",
    "        'total_evaluations': len(RANDOM_SEEDS) * N_SPLITS,\n",
    "        'note': 'Resumed after FedProx - contains q-FedAvg, SCAFFOLD, FedAdam for all configs'\n",
    "    },\n",
    "    'federated_learning': fl_results,\n",
    "    'baseline_reference': baseline_results\n",
    "}\n",
    "\n",
    "json_path = os.path.join(models_dir, 'fl_continue_results.json')\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(results_json, f, indent=2, default=lambda x: float(x) if isinstance(x, np.floating) else x)\n",
    "print(f\"‚úì Saved: fl_continue_results.json\")\n",
    "\n",
    "# Save comparison CSV\n",
    "fl_csv_path = os.path.join(models_dir, 'fl_vs_baseline.csv')\n",
    "fl_comparison_df.to_csv(fl_csv_path, index=False)\n",
    "print(f\"‚úì Saved: fl_vs_baseline.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL RESULTS SAVED\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23986adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== PHASE 4: VISUALIZATIONS ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# FL Comparison Plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Federated Learning vs Baseline - 5-Fold CV √ó 5 Runs (Continued)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (dataset, model) in enumerate([('diabetes', 'LR'), ('diabetes', 'FNN'), ('adult', 'LR'), ('adult', 'FNN')]):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    # Filter data\n",
    "    subset = fl_comparison_df[(fl_comparison_df['Dataset'] == dataset) & (fl_comparison_df['Model'] == model)]\n",
    "    \n",
    "    if len(subset) == 0:\n",
    "        ax.text(0.5, 0.5, 'No data yet', ha='center', va='center', transform=ax.transAxes)\n",
    "        ax.set_title(f'{dataset.upper()} - {model}')\n",
    "        continue\n",
    "    \n",
    "    x = range(len(subset))\n",
    "    baseline_line = subset['Baseline'].iloc[0]\n",
    "    \n",
    "    # Bar plot with error bars\n",
    "    ax.bar(x, subset['FL_Accuracy'], yerr=subset['FL_Std'], capsize=5, alpha=0.7, label='FL Accuracy')\n",
    "    ax.axhline(y=baseline_line, color='red', linestyle='--', linewidth=2, label='Baseline')\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(subset['Aggregation'], rotation=45, ha='right')\n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    ax.set_title(f'{dataset.upper()} - {model}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "fl_viz_path = os.path.join(models_dir, 'fl_comparison.png')\n",
    "plt.savefig(fl_viz_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úì Saved: fl_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VISUALIZATIONS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205e365e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook continues FL training after FedProx:\n",
    "\n",
    "1. **Skipped**: FedAvg and FedProx (already completed)\n",
    "2. **Training**: q-FedAvg, SCAFFOLD, FedAdam for all dataset/model combinations\n",
    "3. **Total**: 18 remaining configurations (3 methods √ó 2 datasets √ó 2 models √ó 25 evaluations each)\n",
    "4. **Statistical Analysis**: T-tests comparing FL against baseline with p-values\n",
    "5. **Results Export**: JSON, CSV files with comprehensive statistics\n",
    "6. **Visualizations**: Comparison charts showing mean ¬± std\n",
    "\n",
    "Estimated runtime: 4-6 hours on Kaggle GPU."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
