{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fb403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== SETUP DIRECTORIES ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SETUP - LOADING PREVIOUS RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Output directory (works on any Kaggle account)\n",
    "try:\n",
    "    output_dir = \"/kaggle/working/fl_adult_analysis\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"‚úì Running on Kaggle - Output: {output_dir}\")\n",
    "except:\n",
    "    output_dir = os.path.join(r\"c:\\Users\\almir\\ai-privacy\\backend\", \"fl_adult_analysis\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"‚úì Running locally - Output: {output_dir}\")\n",
    "\n",
    "# Try to find FL results from previous run\n",
    "fl_results_path = None\n",
    "try:\n",
    "    # Try Kaggle input datasets first\n",
    "    fl_paths = glob.glob('/kaggle/input/*/fl_adult_results.json')\n",
    "    if fl_paths:\n",
    "        fl_results_path = fl_paths[0]\n",
    "        print(f\"‚úì Found FL results in Kaggle input: {fl_results_path}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if not fl_results_path:\n",
    "    # Try local backend folder\n",
    "    local_path = os.path.join(r\"c:\\Users\\almir\\ai-privacy\\backend\", \"models_fl_adult\", \"fl_adult_results.json\")\n",
    "    if os.path.exists(local_path):\n",
    "        fl_results_path = local_path\n",
    "        print(f\"‚úì Found FL results locally: {fl_results_path}\")\n",
    "    else:\n",
    "        print(\"‚ùå ERROR: Could not find fl_adult_results.json\")\n",
    "        print(\"   Please add the FL results as a Kaggle dataset or ensure it exists locally\")\n",
    "        raise FileNotFoundError(\"fl_adult_results.json not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819d168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== LOAD RESULTS ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING FL AND BASELINE RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load FL results\n",
    "with open(fl_results_path, 'r') as f:\n",
    "    fl_data = json.load(f)\n",
    "\n",
    "fl_results = fl_data['federated_learning']\n",
    "print(f\"‚úì Loaded FL results: {len(fl_results)} configurations\")\n",
    "\n",
    "# Load baseline results\n",
    "baseline_results = None\n",
    "try:\n",
    "    # Try Kaggle input first\n",
    "    baseline_paths = glob.glob('/kaggle/input/*/research_results.json')\n",
    "    if baseline_paths:\n",
    "        with open(baseline_paths[0], 'r') as f:\n",
    "            baseline_data = json.load(f)\n",
    "        print(f\"‚úì Loaded baseline from Kaggle input\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if not baseline_results:\n",
    "    # Try local\n",
    "    try:\n",
    "        baseline_path = os.path.join(r\"c:\\Users\\almir\\ai-privacy\\backend\", \"models_research\", \"research_results.json\")\n",
    "        with open(baseline_path, 'r') as f:\n",
    "            baseline_data = json.load(f)\n",
    "        print(f\"‚úì Loaded baseline locally\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è  Baseline results not found - will skip baseline comparison\")\n",
    "        baseline_data = None\n",
    "\n",
    "# Extract baseline for adult dataset\n",
    "if baseline_data:\n",
    "    baseline_results = {}\n",
    "    for model in ['LR', 'FNN']:\n",
    "        key = f\"adult_{model}\"\n",
    "        baseline_results[key] = {\n",
    "            'accuracy': baseline_data['baseline_results']['adult'][model]['accuracy']['mean'],\n",
    "            'all_accuracies': baseline_data['baseline_results']['adult'][model]['all_accuracies']\n",
    "        }\n",
    "    print(f\"‚úì Extracted baseline for Adult dataset: {len(baseline_results)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c10ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== STATISTICAL ANALYSIS ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL ANALYSIS - FL vs BASELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if baseline_results:\n",
    "    fl_comparison = []\n",
    "    \n",
    "    for config_key, fl_config in fl_results.items():\n",
    "        baseline_key = f\"adult_{fl_config['model']}\"\n",
    "        baseline_acc = baseline_results[baseline_key]['accuracy']\n",
    "        baseline_all = baseline_results[baseline_key]['all_accuracies']\n",
    "        \n",
    "        fl_acc = fl_config['accuracy']['mean']\n",
    "        fl_all = fl_config['all_accuracies']\n",
    "        accuracy_loss = baseline_acc - fl_acc\n",
    "        \n",
    "        # T-test\n",
    "        t_stat, p_value = stats.ttest_ind(baseline_all, fl_all)\n",
    "        \n",
    "        fl_comparison.append({\n",
    "            'Model': fl_config['model'],\n",
    "            'Aggregation': fl_config['aggregation'],\n",
    "            'FL_Accuracy': fl_acc * 100,\n",
    "            'FL_Std': fl_config['accuracy']['std'] * 100,\n",
    "            'Baseline': baseline_acc * 100,\n",
    "            'Accuracy_Loss': accuracy_loss * 100,\n",
    "            't_statistic': t_stat,\n",
    "            'p_value': p_value,\n",
    "            'Significant': 'Yes' if p_value < 0.05 else 'No'\n",
    "        })\n",
    "    \n",
    "    fl_comparison_df = pd.DataFrame(fl_comparison)\n",
    "    print(\"\\n\" + fl_comparison_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Skipping baseline comparison - baseline results not available\")\n",
    "    \n",
    "    # Create summary without baseline\n",
    "    fl_summary = []\n",
    "    for config_key, fl_config in fl_results.items():\n",
    "        fl_summary.append({\n",
    "            'Model': fl_config['model'],\n",
    "            'Aggregation': fl_config['aggregation'],\n",
    "            'FL_Accuracy': fl_config['accuracy']['mean'] * 100,\n",
    "            'FL_Std': fl_config['accuracy']['std'] * 100,\n",
    "            'FL_Min': fl_config['accuracy']['min'] * 100,\n",
    "            'FL_Max': fl_config['accuracy']['max'] * 100,\n",
    "            'F1_Score': fl_config['f1']['mean'] * 100,\n",
    "            'F1_Std': fl_config['f1']['std'] * 100\n",
    "        })\n",
    "    \n",
    "    fl_comparison_df = pd.DataFrame(fl_summary)\n",
    "    print(\"\\n\" + fl_comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3a141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== SAVE ANALYSIS RESULTS ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING ANALYSIS RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save comparison/summary CSV\n",
    "csv_path = os.path.join(output_dir, 'fl_adult_statistical_analysis.csv')\n",
    "fl_comparison_df.to_csv(csv_path, index=False)\n",
    "print(f\"‚úì Saved: fl_adult_statistical_analysis.csv\")\n",
    "\n",
    "# Save combined JSON\n",
    "analysis_json = {\n",
    "    'metadata': {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'analysis_type': 'FL Adult Dataset - Statistical Analysis',\n",
    "        'source': 'Continuation from fl_adult_crossvalidation.ipynb'\n",
    "    },\n",
    "    'statistical_comparison': fl_comparison_df.to_dict('records'),\n",
    "    'fl_results': fl_results\n",
    "}\n",
    "\n",
    "if baseline_results:\n",
    "    analysis_json['baseline_reference'] = baseline_results\n",
    "\n",
    "json_path = os.path.join(output_dir, 'fl_adult_analysis_complete.json')\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(analysis_json, f, indent=2, default=lambda x: float(x) if isinstance(x, np.floating) else x)\n",
    "print(f\"‚úì Saved: fl_adult_analysis_complete.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS RESULTS SAVED\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91443c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== VISUALIZATIONS ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# FL Comparison Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Federated Learning - Adult Dataset Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, model in enumerate(['LR', 'FNN']):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    subset = fl_comparison_df[fl_comparison_df['Model'] == model]\n",
    "    \n",
    "    x = range(len(subset))\n",
    "    \n",
    "    # Bar plot with error bars\n",
    "    ax.bar(x, subset['FL_Accuracy'], yerr=subset['FL_Std'], capsize=5, alpha=0.7, label='FL Accuracy')\n",
    "    \n",
    "    # Add baseline line if available\n",
    "    if baseline_results and 'Baseline' in subset.columns:\n",
    "        baseline_line = subset['Baseline'].iloc[0]\n",
    "        ax.axhline(y=baseline_line, color='red', linestyle='--', linewidth=2, label='Baseline')\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(subset['Aggregation'], rotation=45, ha='right')\n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax.set_title(f'Adult - {model}', fontsize=14)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "viz_path = os.path.join(output_dir, 'fl_adult_comparison.png')\n",
    "plt.savefig(viz_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úì Saved: fl_adult_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VISUALIZATIONS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c25795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== SUMMARY STATISTICS ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä FL Performance Summary:\")\n",
    "print(\"\\nLogistic Regression (LR):\")\n",
    "lr_subset = fl_comparison_df[fl_comparison_df['Model'] == 'LR']\n",
    "for _, row in lr_subset.iterrows():\n",
    "    print(f\"  {row['Aggregation']:12s}: {row['FL_Accuracy']:.2f}% ¬± {row['FL_Std']:.2f}%\")\n",
    "\n",
    "print(\"\\nFeedforward Neural Network (FNN):\")\n",
    "fnn_subset = fl_comparison_df[fl_comparison_df['Model'] == 'FNN']\n",
    "for _, row in fnn_subset.iterrows():\n",
    "    print(f\"  {row['Aggregation']:12s}: {row['FL_Accuracy']:.2f}% ¬± {row['FL_Std']:.2f}%\")\n",
    "\n",
    "if baseline_results and 'Accuracy_Loss' in fl_comparison_df.columns:\n",
    "    print(\"\\nüìâ Accuracy Loss vs Baseline:\")\n",
    "    print(f\"  LR  - Mean Loss: {lr_subset['Accuracy_Loss'].mean():.2f}%\")\n",
    "    print(f\"  FNN - Mean Loss: {fnn_subset['Accuracy_Loss'].mean():.2f}%\")\n",
    "    \n",
    "    significant_count = fl_comparison_df[fl_comparison_df['Significant'] == 'Yes'].shape[0]\n",
    "    total_count = len(fl_comparison_df)\n",
    "    print(f\"\\nüìà Statistical Significance:\")\n",
    "    print(f\"  {significant_count}/{total_count} comparisons show significant difference (p < 0.05)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ANALYSIS COMPLETE - All results saved to:\", output_dir)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e014393",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook continues the FL Adult analysis by:\n",
    "\n",
    "1. **Loading Results**: Imports FL results from previous training run (works on any Kaggle account)\n",
    "2. **Statistical Analysis**: Compares FL against baseline with t-tests (if baseline available)\n",
    "3. **Visualizations**: Generates comparison charts showing mean ¬± std\n",
    "4. **Export**: Saves analysis to `/kaggle/working/fl_adult_analysis/` (portable across Kaggle accounts)\n",
    "\n",
    "**Input Requirements**:\n",
    "- FL results: Add `fl_adult_results.json` as a Kaggle dataset input\n",
    "- Baseline results (optional): Add `research_results.json` as a Kaggle dataset input\n",
    "\n",
    "**Outputs**:\n",
    "- `fl_adult_statistical_analysis.csv`: Comparison table\n",
    "- `fl_adult_analysis_complete.json`: Complete analysis results\n",
    "- `fl_adult_comparison.png`: Visualization"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
